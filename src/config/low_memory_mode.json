{
    "TrainingArguments": {
        "output_dir": "low_memory_mode",
        "num_train_epochs": 200,
        "per_device_train_batch_size": 3,
        "evaluation_strategy": "steps",
        "save_strategy": "steps",
        "save_steps": 40,
        "save_total_limit": 4,
        "eval_steps": 20
    },
    "peft": {
        "lora": {
            "lora_alpha": 16,
            "lora_dropout": 0.1,
            "r": 64,
            "bias":"none",
            "task_type":"CAUSAL_LM"
        }
    }
}